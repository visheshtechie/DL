{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras-2DCNN.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/visheshtechie/DL/blob/master/Lab9_Keras_2DCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJnkRBWnx3et",
        "colab_type": "text"
      },
      "source": [
        "#Conv2D\n",
        "\n",
        "```\n",
        "keras.layers.Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)\n",
        "```\n",
        "\n",
        "##2D convolution layer (e.g. spatial convolution over images).\n",
        "\n",
        "This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs. If use_bias is True, a bias vector is created and added to the outputs. Finally, if activation is not None, it is applied to the outputs.\n",
        "\n",
        "When using this layer as the first layer in a model, provide the keyword argument input_shape (tuple of integers, does not include the batch axis), e.g. input_shape=(128, 128, 3) for 128x128 RGB pictures in data_format=\"channels_last\".\n",
        "\n",
        "##Arguments\n",
        "\n",
        "1. filters: Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution).\n",
        "2. kernel_size: An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window. Can be a single integer to specify the same value for all spatial dimensions.\n",
        "3. strides: An integer or tuple/list of 2 integers, specifying the strides of the convolution along the height and width. Can be a single integer to specify the same value for all spatial dimensions. Specifying any stride value != 1 is incompatible with specifying any dilation_rate value != 1.\n",
        "4. padding: one of \"valid\" or \"same\" (case-insensitive). Note that \"same\" is slightly inconsistent across backends with strides != 1, as described here\n",
        "5. data_format: A string, one of \"channels_last\" or \"channels_first\". The ordering of the dimensions in the inputs. \"channels_last\" corresponds to inputs with shape (batch, height, width, channels) while \"channels_first\" corresponds to inputs with shape (batch, channels, height, width). It defaults to the image_data_format value found in your Keras config file at ~/.keras/keras.json. If you never set it, then it will be \"channels_last\".\n",
        "6. dilation_rate: an integer or tuple/list of 2 integers, specifying the dilation rate to use for dilated convolution. Can be a single integer to specify the same value for all spatial dimensions. Currently, specifying any dilation_rate value != 1 is incompatible with specifying any stride value != 1.\n",
        "7. activation: Activation function to use (see activations). If you don't specify anything, no activation is applied (ie. \"linear\" activation: a(x) = x).\n",
        "8. use_bias: Boolean, whether the layer uses a bias vector.\n",
        "9. kernel_initializer: Initializer for the kernel weights matrix (see initializers).\n",
        "10. bias_initializer: Initializer for the bias vector (see initializers).\n",
        "11. kernel_regularizer: Regularizer function applied to the kernel weights matrix (see regularizer).\n",
        "12. bias_regularizer: Regularizer function applied to the bias vector (see regularizer).\n",
        "13. activity_regularizer: Regularizer function applied to the output of the layer (its \"activation\"). (see regularizer).\n",
        "14. kernel_constraint: Constraint function applied to the kernel matrix (see constraints).\n",
        "15. bias_constraint: Constraint function applied to the bias vector (see constraints).\n",
        "\n",
        "##Input shape\n",
        "\n",
        "4D tensor with shape: (batch, channels, rows, cols) if data_format is \"channels_first\" or 4D tensor with shape: (batch, rows, cols, channels) if data_format is \"channels_last\".\n",
        "\n",
        "##Output shape\n",
        "\n",
        "4D tensor with shape: (batch, filters, new_rows, new_cols) if data_format is \"channels_first\" or 4D tensor with shape: (batch, new_rows, new_cols, filters) if data_format is \"channels_last\". rows and cols values might have changed due to padding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWbwssXqyzcq",
        "colab_type": "text"
      },
      "source": [
        "#Aim\n",
        "\n",
        "To classify images as Cats or Dogs\n",
        "\n",
        "#High-level steps to build the CNN to classify images are\n",
        "1. Create convolutional layers by applying kernel or feature maps\n",
        "2. Apply Max pool for translational invariance\n",
        "3. Flatten the inputs\n",
        "4. Create a Fully connected neural network\n",
        "5. Train the model\n",
        "6. Predict the output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7j-zvJkzxryj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "#Input image dimensions\n",
        "img_rows, img_cols = 32, 32\n",
        "num_classes = 2\n",
        "#The data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#Only look at cats [=3] and dogs [=5]\n",
        "train_picks = np.ravel(np.logical_or(y_train==3,y_train==5))  \n",
        "test_picks = np.ravel(np.logical_or(y_test==3,y_test==5))\n",
        "y_train = np.array(y_train[train_picks]==5,dtype=int)\n",
        "y_test = np.array(y_test[test_picks]==5,dtype=int)\n",
        "x_train = x_train[train_picks]\n",
        "x_test = x_test[test_picks]\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 3, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 3, img_rows, img_cols)\n",
        "    input_shape = (3, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 3)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
        "    input_shape = (img_rows, img_cols, 3)\n",
        "    \n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "#Look at the first 9 images from the dataset\n",
        "images = range(0,9)\n",
        "for i in images:\n",
        "    plt.subplot(330 + 1 + i)\n",
        "    plt.imshow(x_train[i], cmap=plt.get_cmap('gray'))\n",
        "    \n",
        "#Show the plot\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmtoJD-0zNPe",
        "colab_type": "text"
      },
      "source": [
        "#Building CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46NiSB1BzOE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "classifier = Sequential()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mIs-QaqzW1X",
        "colab_type": "text"
      },
      "source": [
        "#Create 2D CNN layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4q4iLJ1zYS9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Conv2D\n",
        "\n",
        "classifier.add(Conv2D(filters=32, kernel_size=(3,3),strides=(1, 1), input_shape=(32,32,3), activation='relu',padding='same'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzVn5Z630ZBg",
        "colab_type": "text"
      },
      "source": [
        "#Max pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZVxdQD70YTQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import MaxPooling2D\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUtDwMnM0jsS",
        "colab_type": "text"
      },
      "source": [
        "#Add CNN and max pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPZNcl_p0iiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu',padding='same'))\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msEhg44GVOHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu',padding='same'))\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzpkWCB6VPWL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu',padding='same'))\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wc4jyS_0rYx",
        "colab_type": "text"
      },
      "source": [
        "#Flatten"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfH8KjDQ0rla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Flatten\n",
        "classifier.add(Flatten())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvPNYiat0wPq",
        "colab_type": "text"
      },
      "source": [
        "#Add dense and dropout layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWYsIn5y0wrZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "classifier.add(Dense(units=128, activation='relu'))\n",
        "classifier.add(Dropout(rate=0.2))\n",
        "classifier.add(Dense(units=64, activation='relu'))\n",
        "classifier.add(Dropout(rate=0.2))\n",
        "classifier.add(Dense(units=32, activation='relu'))\n",
        "classifier.add(Dropout(rate=0.2))\n",
        "classifier.add(Dense(units=1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95n47zS_079b",
        "colab_type": "text"
      },
      "source": [
        "#Compile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyHctUru06M2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.compile( optimizer='adadelta', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQVLopQH1aGu",
        "colab_type": "text"
      },
      "source": [
        "#Image generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWxiXIeR1bru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# Rotate images by 90 degrees\n",
        "\n",
        "datagen = ImageDataGenerator(rotation_range=90, rescale=1./255,\n",
        " shear_range=0.2,\n",
        " zoom_range=0.2,\n",
        " horizontal_flip=True,\n",
        " vertical_flip=True,\n",
        " width_shift_range=.2, \n",
        " height_shift_range=.2, \n",
        " fill_mode='nearest', \n",
        " validation_split=0.2)\n",
        "\n",
        "\n",
        "train_generator = datagen.flow(x_train, y_train, batch_size=32,subset='training')\n",
        " \n",
        "validation_generator = datagen.flow(x_train, y_train, batch_size=32,subset='validation')\n",
        "\n",
        "\n",
        "# fit parameters from data\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgYdszFxiqnm",
        "colab_type": "text"
      },
      "source": [
        "#Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeJ3sB4TiqI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classifier.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFmQTSjLoIp_",
        "colab_type": "text"
      },
      "source": [
        "#Plot models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNT_k_swoKTX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(classifier, to_file='model.png',show_shapes=True,show_layer_names=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnJotjXi1-T7",
        "colab_type": "text"
      },
      "source": [
        "#Fit model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3pCSwqn2AqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fits the model on batches with real-time data augmentation:\n",
        "history = classifier.fit(x_train,y_train,batch_size=32,epochs=10,validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVRUva1ejecE",
        "colab_type": "text"
      },
      "source": [
        "#History"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_8dNqCTjvJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UNZwsEk6FeN",
        "colab_type": "text"
      },
      "source": [
        "#Exercise 2: Cat / Dog classifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuxRv3CI6UfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "\n",
        "\n",
        "# Initialising the CNN\n",
        "classifier = Sequential()\n",
        "# Step 1 — Convolution\n",
        "classifier.add(Conv2D(32, (3, 3), input_shape = (32, 32, 3), activation = 'relu'))\n",
        "# Step 2 — Pooling\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "# Adding a second convolutional layer\n",
        "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "# Step 3 — Flattening\n",
        "classifier.add(Flatten())\n",
        "# Step 4 — Full connection\n",
        "classifier.add(Dense(units = 128, activation = 'relu'))\n",
        "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "# Compiling the CNN we shall use the Adam stochastic optimisation method, binary cross entropy loss function\n",
        "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "# Rotate images by 90 degrees\n",
        "datagen = ImageDataGenerator(rotation_range=90, rescale=1./255,\n",
        " shear_range=0.2,\n",
        " zoom_range=0.2,\n",
        " horizontal_flip=True,\n",
        " vertical_flip=True,\n",
        " width_shift_range=.2, height_shift_range=.2, fill_mode='nearest')\n",
        "\n",
        "# fit parameters from data\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# fits the model on batches with real-time data augmentation:\n",
        "classifier.fit_generator(datagen.flow(x_train, y_train, batch_size=32),\n",
        "                    steps_per_epoch=len(x_train) / 32, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSisXrJ19up3",
        "colab_type": "text"
      },
      "source": [
        "#Exercise 3: Building a Convolutional Neural Network (CNN) in Keras for MNIST\n",
        "\n",
        "In this tutorial, we will use the popular mnist dataset. This dataset consists of 70,000 images of handwritten digits from 0–9. We will attempt to identify them using a CNN.\n",
        "\n",
        "##Loading the dataset\n",
        "\n",
        "The mnist dataset is conveniently provided to us as part of the Keras library, so we can easily load the dataset. Out of the 70,000 images provided in the dataset, 60,000 are given for training and 10,000 are given for testing.\n",
        "\n",
        "When we load the dataset below, X_train and X_test will contain the images, and y_train and y_test will contain the digits that those images represent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQleBMsF96hW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "#download mnist data and split into train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOgK6zbU-Ak-",
        "colab_type": "text"
      },
      "source": [
        "#Exploratory data analysis\n",
        "Now let’s take a look at one of the images in our dataset to see what we are working with. We will plot the first image in our dataset and check its size using the ‘shape’ function.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlBl0egm-DA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#plot the first image in the dataset\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg9aeMts-Hl2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check image shape\n",
        "X_train[0].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsrswM7R-XOe",
        "colab_type": "text"
      },
      "source": [
        "#Data pre-processing\n",
        "\n",
        "Next, we need to reshape our dataset inputs (X_train and X_test) to the shape that our model expects when we train the model. The first number is the number of images (60,000 for X_train and 10,000 for X_test). Then comes the shape of each image (28x28). The last number is 1, which signifies that the images are greyscale."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-LnN4BR-ZBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reshape data to fit model\n",
        "X_train = X_train.reshape(60000,28,28,1)\n",
        "X_test = X_test.reshape(10000,28,28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW69bs_F-chf",
        "colab_type": "text"
      },
      "source": [
        "We need to ‘one-hot-encode’ our target variable. This means that a column will be created for each output category and a binary variable is inputted for each category. For example, we saw that the first image in the dataset is a 5. This means that the sixth number in our array will have a 1 and the rest of the array will be filled with 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRRR4CeC-fa-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "#one-hot encode target column\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "y_train[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ghe_Ynz-jze",
        "colab_type": "text"
      },
      "source": [
        "#Building the model\n",
        "\n",
        "Now we are ready to build our model. Here is the code:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xd22iRvU-lGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten\n",
        "#create model\n",
        "model = Sequential()\n",
        "#add model layers\n",
        "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiDyhuqt-uMO",
        "colab_type": "text"
      },
      "source": [
        "#Compiling the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFe0Wo3E-vB-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compile model using accuracy to measure model performance\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIdIfyUyn1SK",
        "colab_type": "text"
      },
      "source": [
        "#Plot model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_-O6a2Fn8wV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png',show_shapes=True,show_layer_names=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QAyeb90oQoo",
        "colab_type": "text"
      },
      "source": [
        "#Model summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_002H9ktoSHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JEqDtXu-6-O",
        "colab_type": "text"
      },
      "source": [
        "#Model fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY7XzAwl-8Vu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdgRJWJ5oUvn",
        "colab_type": "text"
      },
      "source": [
        "#Plot history"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNERBbnVoWPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkzOMYolBOCC",
        "colab_type": "text"
      },
      "source": [
        "#Using our model to make predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKa4bvZ6BPDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#predict first 4 images in the test set\n",
        "model.predict(X_test[:4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhmQ_uPZBWIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#actual results for first 4 images in test set\n",
        "y_test[:4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zf4pDRSYBa3x",
        "colab_type": "text"
      },
      "source": [
        "#Error in classification\n",
        "Image 4 was misclassified as class 3 when it was in Class 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQTIxD5W5MB7",
        "colab_type": "text"
      },
      "source": [
        "#Thank you for completing this notebook"
      ]
    }
  ]
}
