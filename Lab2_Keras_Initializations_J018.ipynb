{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R7HfTHNo-aXK"
   },
   "source": [
    "#Usage of initializers\n",
    "\n",
    "Initializations define the way to set the initial random weights of Keras layers.\n",
    "\n",
    "The keyword arguments used for passing initializers to layers will depend on the layer. Usually it is simply kernel_initializer and bias_initializer:\n",
    "\n",
    "Lets test the various initializations of weights on our baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a8WJIsdG_Sz_"
   },
   "source": [
    "# Baseline model for classification on CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "09sdc-v8-HTt"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:46: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "50000/50000 [==============================] - 21s 424us/step - loss: 1.9272 - acc: 0.3087 - val_loss: 1.7045 - val_acc: 0.3875\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 19s 389us/step - loss: 1.6817 - acc: 0.3933 - val_loss: 1.7284 - val_acc: 0.3811\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 21s 411us/step - loss: 1.5832 - acc: 0.4311 - val_loss: 1.5392 - val_acc: 0.4552\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 21s 426us/step - loss: 1.5221 - acc: 0.4556 - val_loss: 1.5272 - val_acc: 0.4558\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 21s 420us/step - loss: 1.4735 - acc: 0.4715 - val_loss: 1.4711 - val_acc: 0.4681\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#import dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "#change shape from image to vector\n",
    "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
    "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
    "\n",
    "#preprocess\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "#change labels from numeric to one hot encoded\n",
    "Y_train = to_categorical(y_train, 10)\n",
    "Y_test =  to_categorical(y_test, 10)\n",
    "\n",
    "#Model building\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(3072, )))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    " \n",
    "\n",
    "# training\n",
    "history = model.fit(X_train, Y_train,\n",
    "                        batch_size=128,\n",
    "                        nb_epoch=5,\n",
    "                        verbose=1,\n",
    "                        validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ymoVRayJ_v1V"
   },
   "source": [
    "# Model with Initializer as random uniform and zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LavTm0MQ_6ZO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:46: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 20s 407us/step - loss: 1.8724 - acc: 0.3155 - val_loss: 1.7532 - val_acc: 0.3511\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 22s 439us/step - loss: 1.6706 - acc: 0.3990 - val_loss: 1.6551 - val_acc: 0.3972\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 21s 430us/step - loss: 1.5769 - acc: 0.4356 - val_loss: 1.5536 - val_acc: 0.4487\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 21s 421us/step - loss: 1.5071 - acc: 0.4594 - val_loss: 1.4880 - val_acc: 0.4723\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 21s 425us/step - loss: 1.4636 - acc: 0.4745 - val_loss: 1.5179 - val_acc: 0.4498\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#import dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "#change shape from image to vector\n",
    "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
    "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
    "\n",
    "#preprocess\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "#change labels from numeric to one hot encoded\n",
    "Y_train = to_categorical(y_train, 10)\n",
    "Y_test =  to_categorical(y_test, 10)\n",
    "\n",
    "#Model building\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(3072,), kernel_initializer='random_uniform', bias_initializer='zeros'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512, kernel_initializer='random_uniform', bias_initializer='zeros'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512, kernel_initializer='random_uniform', bias_initializer='zeros'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10, kernel_initializer='random_uniform', bias_initializer='zeros'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    " \n",
    "\n",
    "# training\n",
    "history = model.fit(X_train, Y_train,\n",
    "                        batch_size=128,\n",
    "                        nb_epoch=5,\n",
    "                        verbose=1,\n",
    "                        validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ysqToiwvBVae"
   },
   "source": [
    "# Model with Weights as Ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3hy37WX9Bm3x"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:46: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 22s 435us/step - loss: 14.4666 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 22s 432us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 20s 404us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 22s 436us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 22s 448us/step - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#import dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "#change shape from image to vector\n",
    "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
    "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
    "\n",
    "#preprocess\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "#change labels from numeric to one hot encoded\n",
    "Y_train = to_categorical(y_train, 10)\n",
    "Y_test =  to_categorical(y_test, 10)\n",
    "\n",
    "#Model building\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(3072,), kernel_initializer='ones', bias_initializer='ones'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512, kernel_initializer='ones', bias_initializer='ones'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512, kernel_initializer='ones', bias_initializer='ones'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10, kernel_initializer='ones', bias_initializer='ones'))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    " \n",
    "\n",
    "# training\n",
    "history = model.fit(X_train, Y_train,\n",
    "                        batch_size=128,\n",
    "                        nb_epoch=5,\n",
    "                        verbose=1,\n",
    "                        validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wt4hjq_eCFyu"
   },
   "source": [
    "# Model initialized with constant values\n",
    "\n",
    "Initializer that generates tensors initialized to a constant value.\n",
    "\n",
    "Arguments\n",
    "\n",
    "1. value: float; the value of the generator tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iLAIW3w0COQV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:48: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 21s 424us/step - loss: 2.3027 - acc: 0.0977 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 20s 406us/step - loss: 2.3027 - acc: 0.0976 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 20s 405us/step - loss: 2.3027 - acc: 0.0980 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 20s 406us/step - loss: 2.3027 - acc: 0.0987 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 2.3027 - acc: 0.0981 - val_loss: 2.3026 - val_acc: 0.1000\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#import dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "#change shape from image to vector\n",
    "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
    "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
    "\n",
    "#preprocess\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "#change labels from numeric to one hot encoded\n",
    "Y_train = to_categorical(y_train, 10)\n",
    "Y_test =  to_categorical(y_test, 10)\n",
    "\n",
    "#Model building\n",
    "initializer = keras.initializers.Constant(value=0)\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(3072,), kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    " \n",
    "\n",
    "# training\n",
    "history = model.fit(X_train, Y_train,\n",
    "                        batch_size=128,\n",
    "                        nb_epoch=5,\n",
    "                        verbose=1,\n",
    "                        validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sA0dnI8SCuBG"
   },
   "source": [
    "#RandomNormal\n",
    "keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "Initializer that generates tensors with a normal distribution.\n",
    "\n",
    "Arguments\n",
    "\n",
    "1. mean: a python scalar or a scalar tensor. Mean of the random values to generate.\n",
    "2. stddev: a python scalar or a scalar tensor. Standard deviation of the random values to generate.\n",
    "3. seed: A Python integer. Used to seed the random generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hp1NkCnlDFIu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:48: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 18s 351us/step - loss: 1.9210 - acc: 0.3143 - val_loss: 1.6972 - val_acc: 0.3894\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 17s 337us/step - loss: 1.6608 - acc: 0.4048 - val_loss: 1.7036 - val_acc: 0.3978\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 17s 332us/step - loss: 1.5677 - acc: 0.4365 - val_loss: 1.5263 - val_acc: 0.4538\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 17s 331us/step - loss: 1.4987 - acc: 0.4650 - val_loss: 1.5550 - val_acc: 0.4429\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 17s 330us/step - loss: 1.4512 - acc: 0.4798 - val_loss: 1.4921 - val_acc: 0.4645\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#import dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "#change shape from image to vector\n",
    "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
    "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
    "\n",
    "#preprocess\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "#change labels from numeric to one hot encoded\n",
    "Y_train = to_categorical(y_train, 10)\n",
    "Y_test =  to_categorical(y_test, 10)\n",
    "\n",
    "#Model building\n",
    "initializer = keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(3072,), kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    " \n",
    "\n",
    "# training\n",
    "history = model.fit(X_train, Y_train,\n",
    "                        batch_size=128,\n",
    "                        nb_epoch=5,\n",
    "                        verbose=1,\n",
    "                        validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3K_gczVbDMRC"
   },
   "source": [
    "#RandomUniform\n",
    "keras.initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=None)\n",
    "Initializer that generates tensors with a uniform distribution.\n",
    "\n",
    "Arguments\n",
    "\n",
    "1. minval: A python scalar or a scalar tensor. Lower bound of the range of random values to generate.\n",
    "2. maxval: A python scalar or a scalar tensor. Upper bound of the range of random values to generate. Defaults to 1 for float types.\n",
    "3. seed: A Python integer. Used to seed the random generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3MTNL18EDR8j"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:48: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 17s 349us/step - loss: 1.8804 - acc: 0.3156 - val_loss: 1.7383 - val_acc: 0.3707\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 16s 328us/step - loss: 1.6712 - acc: 0.3972 - val_loss: 1.6660 - val_acc: 0.4095\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 17s 344us/step - loss: 1.5745 - acc: 0.4341 - val_loss: 1.5275 - val_acc: 0.4565\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 19s 389us/step - loss: 1.5155 - acc: 0.4563 - val_loss: 1.4981 - val_acc: 0.4654\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 18s 364us/step - loss: 1.4627 - acc: 0.4772 - val_loss: 1.4772 - val_acc: 0.4709\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#import dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "#change shape from image to vector\n",
    "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
    "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
    "\n",
    "#preprocess\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "#change labels from numeric to one hot encoded\n",
    "Y_train = to_categorical(y_train, 10)\n",
    "Y_test =  to_categorical(y_test, 10)\n",
    "\n",
    "#Model building\n",
    "initializer = keras.initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=None)\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(3072,), kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    " \n",
    "\n",
    "# training\n",
    "history = model.fit(X_train, Y_train,\n",
    "                        batch_size=128,\n",
    "                        nb_epoch=5,\n",
    "                        verbose=1,\n",
    "                        validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sCx54MFWDgnj"
   },
   "source": [
    "#TruncatedNormal\n",
    "keras.initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "Initializer that generates a truncated normal distribution.\n",
    "\n",
    "These values are similar to values from a RandomNormal except that values more than two standard deviations from the mean are discarded and redrawn. This is the recommended initializer for neural network weights and filters.\n",
    "\n",
    "Arguments\n",
    "\n",
    "1. mean: a python scalar or a scalar tensor. Mean of the random values to generate.\n",
    "2. stddev: a python scalar or a scalar tensor. Standard deviation of the random values to generate.\n",
    "3. seed: A Python integer. Used to seed the random generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r9ty4foYDmBj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:48: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 23s 455us/step - loss: 1.8701 - acc: 0.3242 - val_loss: 1.6696 - val_acc: 0.4105\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 21s 425us/step - loss: 1.6565 - acc: 0.4061 - val_loss: 1.6200 - val_acc: 0.4286\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 21s 415us/step - loss: 1.5674 - acc: 0.4388 - val_loss: 1.5073 - val_acc: 0.4615\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 23s 469us/step - loss: 1.5125 - acc: 0.4582 - val_loss: 1.4989 - val_acc: 0.4550\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 21s 414us/step - loss: 1.4593 - acc: 0.4775 - val_loss: 1.5253 - val_acc: 0.4603\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#import dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "#change shape from image to vector\n",
    "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
    "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
    "\n",
    "#preprocess\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "#change labels from numeric to one hot encoded\n",
    "Y_train = to_categorical(y_train, 10)\n",
    "Y_test =  to_categorical(y_test, 10)\n",
    "\n",
    "#Model building\n",
    "initializer = keras.initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(3072,), kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    " \n",
    "\n",
    "# training\n",
    "history = model.fit(X_train, Y_train,\n",
    "                        batch_size=128,\n",
    "                        nb_epoch=5,\n",
    "                        verbose=1,\n",
    "                        validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X2LU6BByDtCE"
   },
   "source": [
    "#VarianceScaling\n",
    "1. keras.initializers.VarianceScaling(scale=1.0, mode='fan_in', distribution='normal', seed=None)\n",
    "2. Initializer capable of adapting its scale to the shape of weights.\n",
    "\n",
    "With distribution=\"normal\", samples are drawn from a truncated normal distribution centered on zero, with stddev = sqrt(scale / n) where n is:\n",
    "\n",
    "1. number of input units in the weight tensor, if mode = \"fan_in\"\n",
    "2. number of output units, if mode = \"fan_out\"\n",
    "3. average of the numbers of input and output units, if mode = \"fan_avg\"\n",
    "\n",
    "With distribution=\"uniform\", samples are drawn from a uniform distribution within [-limit, limit], with limit = sqrt(3 * scale / n).\n",
    "\n",
    "Arguments\n",
    "\n",
    "1. scale: Scaling factor (positive float).\n",
    "2. mode: One of \"fan_in\", \"fan_out\", \"fan_avg\".\n",
    "3. distribution: Random distribution to use. One of \"normal\", \"uniform\".\n",
    "4. seed: A Python integer. Used to seed the random generator.\n",
    "\n",
    "Raises\n",
    "\n",
    "ValueError: In case of an invalid value for the \"scale\", mode\" or \"distribution\" arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7R-rDZuQD8Yd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:48: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 1.8793 - acc: 0.3160 - val_loss: 1.7297 - val_acc: 0.3718\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 20s 399us/step - loss: 1.6712 - acc: 0.3993 - val_loss: 1.5840 - val_acc: 0.4294\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 20s 396us/step - loss: 1.5760 - acc: 0.4345 - val_loss: 1.5343 - val_acc: 0.4525\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 23s 455us/step - loss: 1.5101 - acc: 0.4587 - val_loss: 1.4886 - val_acc: 0.4653\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 23s 452us/step - loss: 1.4581 - acc: 0.4794 - val_loss: 1.4499 - val_acc: 0.4848\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#import dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "#change shape from image to vector\n",
    "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
    "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
    "\n",
    "#preprocess\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "#change labels from numeric to one hot encoded\n",
    "Y_train = to_categorical(y_train, 10)\n",
    "Y_test =  to_categorical(y_test, 10)\n",
    "\n",
    "#Model building\n",
    "initializer = keras.initializers.VarianceScaling(scale=1.0, mode='fan_in', distribution='normal', seed=None)\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(3072,), kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    " \n",
    "\n",
    "# training\n",
    "history = model.fit(X_train, Y_train,\n",
    "                        batch_size=128,\n",
    "                        nb_epoch=5,\n",
    "                        verbose=1,\n",
    "                        validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Duh3uniqEJOr"
   },
   "source": [
    "#Orthogonal\n",
    "keras.initializers.Orthogonal(gain=1.0, seed=None)\n",
    "Initializer that generates a random orthogonal matrix.\n",
    "\n",
    "Arguments\n",
    "\n",
    "1. gain: Multiplicative factor to apply to the orthogonal matrix.\n",
    "2. seed: A Python integer. Used to seed the random generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "heR04DCHEbx0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:48: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 23s 450us/step - loss: 10.9918 - acc: 0.1594 - val_loss: 1.9049 - val_acc: 0.3048\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 20s 409us/step - loss: 1.7758 - acc: 0.3594 - val_loss: 1.6595 - val_acc: 0.4092\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 24s 471us/step - loss: 1.6307 - acc: 0.4168 - val_loss: 1.6407 - val_acc: 0.4195\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 21s 413us/step - loss: 1.5413 - acc: 0.4473 - val_loss: 1.5584 - val_acc: 0.4437\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 23s 465us/step - loss: 1.4893 - acc: 0.4687 - val_loss: 1.5149 - val_acc: 0.4637\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#import dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "#change shape from image to vector\n",
    "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
    "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
    "\n",
    "#preprocess\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "#change labels from numeric to one hot encoded\n",
    "Y_train = to_categorical(y_train, 10)\n",
    "Y_test =  to_categorical(y_test, 10)\n",
    "\n",
    "#Model building\n",
    "initializer = keras.initializers.Orthogonal(gain=2.0, seed=None)\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(3072,), kernel_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512, kernel_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512, kernel_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10, kernel_initializer=initializer))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    " \n",
    "\n",
    "# training\n",
    "history = model.fit(X_train, Y_train,\n",
    "                        batch_size=128,\n",
    "                        nb_epoch=5,\n",
    "                        verbose=1,\n",
    "                        validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mluQA2hhMdla"
   },
   "source": [
    "#Identity\n",
    "\n",
    "1. keras.initializers.Identity(gain=1.0)\n",
    "2. Initializer that generates the identity matrix.\n",
    "\n",
    "Only use for 2D matrices. If the desired matrix is not square, it gets padded with zeros for the additional rows/columns.\n",
    "\n",
    "Arguments\n",
    "\n",
    "1. gain: Multiplicative factor to apply to the identity matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fb69AfQNErUX"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Long side should be multiple of short side.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-2e60c86888cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m             \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    429\u001b[0m                                          \u001b[1;34m'You can build it manually via: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[1;32m--> 431\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    864\u001b[0m                                       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'kernel'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m                                       \u001b[0mregularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                                       constraint=self.kernel_constraint)\n\u001b[0m\u001b[0;32m    867\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m             self.bias = self.add_weight(shape=(self.units,),\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint)\u001b[0m\n\u001b[0;32m    247\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         weight = K.variable(initializer(shape),\n\u001b[0m\u001b[0;32m    250\u001b[0m                             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m                             \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\keras\\initializers.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, shape, dtype)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Long side should be multiple of short side.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Long side should be multiple of short side."
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#import dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "#change shape from image to vector\n",
    "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
    "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
    "\n",
    "#preprocess\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "#change labels from numeric to one hot encoded\n",
    "Y_train = to_categorical(y_train, 10)\n",
    "Y_test =  to_categorical(y_test, 10)\n",
    "\n",
    "#Model building\n",
    "initializer = keras.initializers.Identity(gain=1.0)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(3072,), kernel_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512, kernel_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512, kernel_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10, kernel_initializer=initializer))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    " \n",
    "\n",
    "# training\n",
    "history = model.fit(X_train, Y_train,\n",
    "                        batch_size=128,\n",
    "                        nb_epoch=5,\n",
    "                        verbose=1,\n",
    "                        validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FqQYkh0MMxGM"
   },
   "source": [
    "#lecun_uniform\n",
    "keras.initializers.lecun_uniform(seed=None)\n",
    "\n",
    "LeCun uniform initializer.\n",
    "\n",
    "It draws samples from a uniform distribution within [-limit, limit] where limit is sqrt(3 / fan_in) where fan_in is the number of input units in the weight tensor.\n",
    "\n",
    "Arguments\n",
    "\n",
    "1. seed: A Python integer. Used to seed the random generator.\n",
    "\n",
    "Returns\n",
    "\n",
    "1. An initializer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JZn_tD8mM7bT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 21s 413us/step - loss: 1.8732 - acc: 0.3224 - val_loss: 1.6827 - val_acc: 0.4001\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 16s 326us/step - loss: 1.6518 - acc: 0.4039 - val_loss: 1.5979 - val_acc: 0.4266\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 18s 357us/step - loss: 1.5645 - acc: 0.4382 - val_loss: 1.5319 - val_acc: 0.4466\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 16s 327us/step - loss: 1.5017 - acc: 0.4622 - val_loss: 1.4661 - val_acc: 0.4771\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 17s 344us/step - loss: 1.4527 - acc: 0.4779 - val_loss: 1.4605 - val_acc: 0.4764\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#import dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "#change shape from image to vector\n",
    "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
    "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
    "\n",
    "#preprocess\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "#change labels from numeric to one hot encoded\n",
    "Y_train = to_categorical(y_train, 10)\n",
    "Y_test =  to_categorical(y_test, 10)\n",
    "\n",
    "#Model building\n",
    "initializer = keras.initializers.lecun_uniform(seed=None)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(3072,), kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    " \n",
    "\n",
    "# training\n",
    "history = model.fit(X_train, Y_train,\n",
    "                        batch_size=128,\n",
    "                        nb_epoch=5,\n",
    "                        verbose=1,\n",
    "                        validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B_5CNXt8NG7q"
   },
   "source": [
    "#glorot_normal\n",
    "\n",
    "keras.initializers.glorot_normal(seed=None)\n",
    "\n",
    "Glorot normal initializer, also called Xavier normal initializer.\n",
    "\n",
    "It draws samples from a truncated normal distribution centered on 0 with stddev = sqrt(2 / (fan_in + fan_out)) where fan_in is the number of input units in the weight tensor and fan_out is the number of output units in the weight tensor.\n",
    "\n",
    "Arguments\n",
    "\n",
    "1. seed: A Python integer. Used to seed the random generator.\n",
    "\n",
    "Returns\n",
    "\n",
    "1. An initializer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jxGxYIQBNZP8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 21s 416us/step - loss: 1.9136 - acc: 0.3156 - val_loss: 1.7137 - val_acc: 0.3837\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 18s 355us/step - loss: 1.6585 - acc: 0.4030 - val_loss: 1.6155 - val_acc: 0.4243\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 18s 361us/step - loss: 1.5701 - acc: 0.4379 - val_loss: 1.5366 - val_acc: 0.4528\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 17s 334us/step - loss: 1.5060 - acc: 0.4634 - val_loss: 1.4771 - val_acc: 0.4762\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 17s 340us/step - loss: 1.4525 - acc: 0.4812 - val_loss: 1.4660 - val_acc: 0.4778\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#import dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "#change shape from image to vector\n",
    "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
    "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
    "\n",
    "#preprocess\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "#change labels from numeric to one hot encoded\n",
    "Y_train = to_categorical(y_train, 10)\n",
    "Y_test =  to_categorical(y_test, 10)\n",
    "\n",
    "#Model building\n",
    "initializer = keras.initializers.glorot_normal(seed=None)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(3072,), kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    " \n",
    "\n",
    "# training\n",
    "history = model.fit(X_train, Y_train,\n",
    "                        batch_size=128,\n",
    "                        nb_epoch=5,\n",
    "                        verbose=1,\n",
    "                        validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V53RcodcNmbd"
   },
   "source": [
    "#glorot_uniform\n",
    "\n",
    "keras.initializers.glorot_uniform(seed=None)\n",
    "\n",
    "Glorot uniform initializer, also called Xavier uniform initializer.\n",
    "\n",
    "It draws samples from a uniform distribution within [-limit, limit] where limit is sqrt(6 / (fan_in + fan_out)) where fan_in is the number of input units in the weight tensor and fan_out is the number of output units in the weight tensor.\n",
    "\n",
    "Arguments\n",
    "\n",
    "1. seed: A Python integer. Used to seed the random generator.\n",
    "\n",
    "Returns\n",
    "\n",
    "1. An initializer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wsVWfqeQNtxl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:50: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 21s 430us/step - loss: 1.8999 - acc: 0.3128 - val_loss: 1.7146 - val_acc: 0.3829\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 18s 357us/step - loss: 1.6593 - acc: 0.4035 - val_loss: 1.6518 - val_acc: 0.4097\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 17s 349us/step - loss: 1.5649 - acc: 0.4397 - val_loss: 1.5462 - val_acc: 0.4437\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 18s 368us/step - loss: 1.5077 - acc: 0.4593 - val_loss: 1.5235 - val_acc: 0.4591\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 1.4541 - acc: 0.4778 - val_loss: 1.4663 - val_acc: 0.4769\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#import dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "#change shape from image to vector\n",
    "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
    "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
    "\n",
    "#preprocess\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "#change labels from numeric to one hot encoded\n",
    "Y_train = to_categorical(y_train, 10)\n",
    "Y_test =  to_categorical(y_test, 10)\n",
    "\n",
    "#Model building\n",
    "initializer = keras.initializers.glorot_uniform(seed=None)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(3072,), kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    " \n",
    "\n",
    "# training\n",
    "history = model.fit(X_train, Y_train,\n",
    "                        batch_size=128,\n",
    "                        nb_epoch=5,\n",
    "                        verbose=1,\n",
    "                        validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1F2aV9rJN0Ez"
   },
   "source": [
    "#he_normal\n",
    "\n",
    "keras.initializers.he_normal(seed=None)\n",
    "\n",
    "He normal initializer.\n",
    "\n",
    "It draws samples from a truncated normal distribution centered on 0 with stddev = sqrt(2 / fan_in) where fan_in is the number of input units in the weight tensor.\n",
    "\n",
    "Arguments\n",
    "\n",
    "1. seed: A Python integer. Used to seed the random generator.\n",
    "\n",
    "Returns\n",
    "\n",
    "An initializer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vUZJTErrN5nc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:52: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 19s 374us/step - loss: 1.9507 - acc: 0.3133 - val_loss: 1.6909 - val_acc: 0.3953\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 16s 326us/step - loss: 1.6690 - acc: 0.3991 - val_loss: 1.6676 - val_acc: 0.4005\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 17s 332us/step - loss: 1.5749 - acc: 0.4353 - val_loss: 1.5189 - val_acc: 0.4533\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 16s 328us/step - loss: 1.5167 - acc: 0.4564 - val_loss: 1.4988 - val_acc: 0.4690\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 16s 329us/step - loss: 1.4661 - acc: 0.4746 - val_loss: 1.4851 - val_acc: 0.4738\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#import dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "#change shape from image to vector\n",
    "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
    "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
    "\n",
    "#preprocess\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "#change labels from numeric to one hot encoded\n",
    "Y_train = to_categorical(y_train, 10)\n",
    "Y_test =  to_categorical(y_test, 10)\n",
    "\n",
    "#Model building\n",
    "initializer = keras.initializers.he_normal(seed=None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(3072,), kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    " \n",
    "\n",
    "# training\n",
    "history = model.fit(X_train, Y_train,\n",
    "                        batch_size=128,\n",
    "                        nb_epoch=5,\n",
    "                        verbose=1,\n",
    "                        validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2fjTgQ2-N6SU"
   },
   "source": [
    "#lecun_normal\n",
    "\n",
    "keras.initializers.lecun_normal(seed=None)\n",
    "\n",
    "LeCun normal initializer.\n",
    "\n",
    "It draws samples from a truncated normal distribution centered on 0 with stddev = sqrt(1 / fan_in) where fan_in is the number of input units in the weight tensor.\n",
    "\n",
    "Arguments\n",
    "\n",
    "1. seed: A Python integer. Used to seed the random generator.\n",
    "\n",
    "Returns\n",
    "\n",
    "1. An initializer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lB14_Gl7N6rA"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:50: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 19s 381us/step - loss: 1.8735 - acc: 0.3212 - val_loss: 1.7109 - val_acc: 0.3774\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 17s 337us/step - loss: 1.6560 - acc: 0.4077 - val_loss: 1.6401 - val_acc: 0.4100\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 17s 335us/step - loss: 1.5667 - acc: 0.4359 - val_loss: 1.5839 - val_acc: 0.4330\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 17s 340us/step - loss: 1.4979 - acc: 0.4629 - val_loss: 1.5986 - val_acc: 0.4403\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 17s 348us/step - loss: 1.4536 - acc: 0.4774 - val_loss: 1.4901 - val_acc: 0.4627\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#import dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "#change shape from image to vector\n",
    "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
    "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
    "\n",
    "#preprocess\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "#change labels from numeric to one hot encoded\n",
    "Y_train = to_categorical(y_train, 10)\n",
    "Y_test =  to_categorical(y_test, 10)\n",
    "\n",
    "#Model building\n",
    "initializer = keras.initializers.lecun_normal(seed=None)\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(3072,), kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    " \n",
    "\n",
    "# training\n",
    "history = model.fit(X_train, Y_train,\n",
    "                        batch_size=128,\n",
    "                        nb_epoch=5,\n",
    "                        verbose=1,\n",
    "                        validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GqMGiXtHN7Ba"
   },
   "source": [
    "#he_uniform\n",
    "\n",
    "keras.initializers.he_uniform(seed=None)\n",
    "\n",
    "He uniform variance scaling initializer.\n",
    "\n",
    "It draws samples from a uniform distribution within [-limit, limit] where limit is sqrt(6 / fan_in) where fan_in is the number of input units in the weight tensor.\n",
    "\n",
    "Arguments\n",
    "\n",
    "1. seed: A Python integer. Used to seed the random generator.\n",
    "\n",
    "Returns\n",
    "\n",
    "An initializer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "60P1yxX6N7PU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 1.9213 - acc: 0.3196 - val_loss: 1.6976 - val_acc: 0.3937\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 17s 345us/step - loss: 1.6615 - acc: 0.4034 - val_loss: 1.5833 - val_acc: 0.4334\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 18s 352us/step - loss: 1.5666 - acc: 0.4395 - val_loss: 1.5845 - val_acc: 0.4422\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 19s 375us/step - loss: 1.5147 - acc: 0.4561 - val_loss: 1.4910 - val_acc: 0.4640\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 18s 358us/step - loss: 1.4585 - acc: 0.4775 - val_loss: 1.4912 - val_acc: 0.4670\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#import dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "#change shape from image to vector\n",
    "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
    "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
    "\n",
    "#preprocess\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255.0\n",
    "X_test /= 255.0\n",
    "\n",
    "#change labels from numeric to one hot encoded\n",
    "Y_train = to_categorical(y_train, 10)\n",
    "Y_test =  to_categorical(y_test, 10)\n",
    "\n",
    "#Model building\n",
    "initializer = keras.initializers.he_uniform(seed=None)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(3072,), kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10, kernel_initializer=initializer, bias_initializer=initializer))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    " \n",
    "\n",
    "# training\n",
    "history = model.fit(X_train, Y_train,\n",
    "                        batch_size=128,\n",
    "                        nb_epoch=5,\n",
    "                        verbose=1,\n",
    "                        validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bHHeipq8N7oE"
   },
   "source": [
    "#Thank you for completing this notebook"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Keras-Initializations.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
